# Отчет по домашнему заданию: Высоконагруженный микросервис на Go

## 1. Сравнительный анализ Go vs Java в high-load сценариях

При разработке высоконагруженных систем выбор между Go и Java требует анализа нескольких ключевых факторов: модели конкурентности, управления памятью, производительности и экосистемы.

### Модель конкурентности (Concurrency)
**Go** использует модель CSP (Communicating Sequential Processes) через **Goroutines** и Channels. Горутины — это "легковесные потоки" (green threads), управляемые рантаймом Go, а не ОС.
- **Преимущества:** Стек горутины начинается с 2 КБ, что позволяет запускать миллионы горутин на одной машине. Переключение контекста очень дешевое.
- **Влияние на High-Load:** Идеально для I/O-bound задач (REST API, прокси). Блокирующие операции (сеть, диск) не блокируют поток ОС, так как планировщик Go паркует горутину и запускает другие. Это позволяет обрабатывать десятки тысяч запросов в секунду (RPS) с минимальными ресурсами.

**Java** традиционно использовала потоки ОС (Thread per Request).
- **Недостатки:** Поток ОС занимает ~1 МБ памяти. Переключение контекста дорогое (syscall). При 10,000 соединений сервер может исчерпать память или CPU на переключениях.
- **Современное решение (Project Loom / Virtual Threads):** В Java 21+ появились виртуальные потоки, приближающие модель к Go. Однако экосистема библиотек все еще адаптируется к ним.

### Управление памятью (Garbage Collection)
**Go GC** оптимизирован на низкую задержку (low latency).
- **Паузы:** Обычно < 1 мс даже на больших кучах.
- **Цена:** Может потреблять больше CPU для поддержания такой низкой задержки (write barriers). Выделение памяти на стеке (escape analysis) работает агрессивнее, чем в Java, снижая нагрузку на GC.

**Java GC** (G1, ZGC, Shenandoah) — мощные и настраиваемые.
- **Пропускная способность (Throughput):** Java часто выигрывает в задачах, требующих максимальной "молотилки" данных (batch processing), так как JIT-компилятор может выполнить более агрессивные оптимизации, чем статический компилятор Go.
- **Latency:** ZGC позволяет получать паузы < 1 мс, но требует более тщательной настройки и потребляет больше памяти.

### Производительность и Старт
- **Go:** Компилируется в нативный бинарный код. Старт мгновенный (< 100 мс). Потребление памяти "холодного" сервиса минимально (10-20 МБ).
- **Java:** Работает на JVM. "Холодный старт" медленнее (JVM init + Class Loading + JIT warmup). Потребление памяти выше (мин. 100-200 МБ для Spring Boot).
- **High-Load вывод:** Для Serverless или микросервисов с частым масштабированием (Kubernetes HPA) Go выигрывает за счет быстрого старта. Для долгоживущих монолитов Java может быть быстрее на пике.

### Итог
**Go** — лучший выбор для сетевых микросервисов, API шлюзов и систем, где критична предсказуемая Latency и низкое потребление ресурсов при большом количестве соединений (C10K problem).
**Java** — предпочтительна для сложных Enterprise-систем с богатой бизнес-логикой и необходимостью интеграции с огромным количеством legacy-библиотек.

---

## 2. Анализ альтернативных решений

### Rust
**Rust** обеспечивает гарантии безопасности памяти без GC (через ownership/borrowing).
- **Плюсы:** Отсутствие GC означает отсутствие пауз. Предсказуемость производительности на уровне C++.
- **Минусы:** Крутая кривая обучения. Разработка медленнее, чем на Go.
- **Пример:** Cloudflare заменили Nginx на прокси на Rust (Pingora), чтобы избежать проблем с памятью и получить безопасность. В нашем случае, Rust позволил бы выжать еще больше RPS, но ценой времени разработки.

### Quarkus / Micronaut (Java Native)
Фреймворки "нового поколения" для Java, ориентированные на GraalVM Native Image.
- **Плюсы:** Компилируют Java в нативный код (AOT). Старт за миллисекунды, память как у Go.
- **Минусы:** Отсутствие динамических возможностей JVM (Reflection ограничен). Долгая компиляция (сборка образа занимает минуты).
- **Сравнение:** Quarkus делает Java конкурентной с Go в облаке, но Go всё еще проще в поддержке и сборке.

---

## 3. Описание реализации интеграции

В проекте были реализованы следующие ключевые компоненты для обеспечения нагрузоустойчивости и наблюдаемости:

1.  **Rate Limiting (Token Bucket):**
    Использован алгоритм Token Bucket (`golang.org/x/time/rate`).
    - **Limit:** 1000 RPS.
    - **Burst:** 5000. Это критически важно. Если burst будет равен 1 или 1000, то микро-всплески трафика могут быть ошибочно отклонены. Burst 5000 позволяет "накопить" токены и пропустить резкий скачок запросов (например, при старте теста), сохраняя среднюю скорость 1000. В коде это реализовано как middleware, оборачивающее все хендлеры.

2.  **Метрики Prometheus:**
    Использована библиотека `prometheus/client_golang`.
    - **Counter (`http_requests_total`):** Подсчет всех запросов с лейблами (method, path).
    - **Histogram (`http_request_duration_seconds`):** Измерение latency. Гистограмма позволяет считать квантили (95-й, 99-й перцентили), что важнее среднего времени.
    - Метрики собираются в middleware и отдаются на `/metrics`.

3.  **Асинхронность:**
    Логирование вынесено в отдельные горутины (`go utils.LogUserAction(...)`). Это убирает операции записи в I/O (консоль/файл) из горячего пути запроса, снижая latency.

4.  **Docker & Compose:**
    Использован `multistage build`. Финальный образ базируется на `alpine`, что делает его размером ~10-15 МБ. Сервис запускается вместе с Prometheus для удобства отладки.

---

## 4. Результаты нагрузочного тестирования (wrk)
*(Вставьте сюда скриншоты выполнения команды `wrk -t12 -c500 -d60s http://localhost:8080/api/users`)*

**Ожидаемые показатели:**
- **RPS:** ~15,000+ (на современных CPU Go http server легко держит >20k на simple responses).
- **Latency:** < 1ms (так как хранилище in-memory).
- **Errors:** 0.

*(Примечание: при запуске через Docker на Windows/Mac возможны накладные расходы на виртуализацию сети, RPS может быть ниже, но точно выше 1000).*
